{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load BTC data\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "def get_data_spec(coin, date, time_period,apiKey):\n",
    "    \"\"\" Query the API for 2000 units historical price data starting from \"date\". \"\"\"\n",
    "    url = \"https://min-api.cryptocompare.com/data/{}?fsym={}&tsym=USD&limit=2000&toTs={}&api_key={}\".format(time_period, coin, date,apiKey)\n",
    "    r = requests.get(url)\n",
    "    ipdata = r.json()\n",
    "    return ipdata\n",
    "\n",
    "def get_news_data_spec(category, timestamp, apiKey, language):\n",
    "    \"\"\" Query the API for 2000 units historical price data starting from \"date\". \"\"\"\n",
    "    url = \"https://min-api.cryptocompare.com/data/v2/news/?categories={}&lang={}&lTs={}&api_key={}\".format(category, language, timestamp ,apiKey)\n",
    "    r = requests.get(url)\n",
    "    ipdata = r.json()\n",
    "    return ipdata\n",
    "\n",
    "def get_social_data_spec(coin, date, time_frequency, aggregate, apiKey):\n",
    "    url = \"https://min-api.cryptocompare.com/data/social/coin/histo/{}?coinId={}&aggregate={}&limit=2000&toTs={}&api_key={}\"\\\n",
    "        .format(time_frequency, coin, aggregate,date,apiKey)\n",
    "    r = requests.get(url)\n",
    "    ipdata = r.json()\n",
    "    return ipdata\n",
    "\n",
    "def get_df_spec(from_date, to_date, time_period, coin, apiKey):\n",
    "    \"\"\" Get historical price data between two dates. If further apart than query limit then query multiple times. \"\"\"\n",
    "    date = to_date\n",
    "    holder = []\n",
    "    while date > from_date:\n",
    "        # Now we use the new function to query specific coins\n",
    "        data = get_data_spec(coin, date, time_period,apiKey)\n",
    "        holder.append(pd.DataFrame(data['Data']))\n",
    "        date = data['TimeFrom']\n",
    "    df = pd.concat(holder, axis = 0)\n",
    "    df = df[df['time']>from_date]\n",
    "    df['date/hour'] = pd.to_datetime(df['time'], unit='s') \n",
    "    df.set_index('date/hour', inplace=True)\n",
    "    df.sort_index(ascending=True, inplace=True)\n",
    "    # And just keep the close price, with the column heading as the name of the coin. \n",
    "    #df.rename(columns={'close':coin}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_social_df_spec(from_date, to_date, time_frequency, coin, aggregate, apiKey):\n",
    "    \"\"\" Get historical price data between two dates. If further apart than query limit then query multiple times. \"\"\"\n",
    "    date = to_date\n",
    "    holder = []\n",
    "    while date > from_date:\n",
    "        # Now we use the new function to query specific coins\n",
    "        data = get_social_data_spec(coin, date, time_frequency, aggregate, apiKey)\n",
    "        data_df = pd.DataFrame(data['Data'])\n",
    "        holder.append(data_df)\n",
    "        date = data_df['time'].min()\n",
    "    df = pd.concat(holder, axis = 0)\n",
    "    df = df[df['time']>from_date]\n",
    "    #df['date/hour'] = pd.to_datetime(df['time'], unit='s') \n",
    "    df.set_index('time', inplace=True)\n",
    "    df.sort_index(ascending=True, inplace=True)\n",
    "    # And just keep the close price, with the column heading as the name of the coin. \n",
    "    #df.rename(columns={'close':coin}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # parameters\n",
    "fromdate = int(datetime.date(2017,1,1).strftime(\"%s\"))\n",
    "todate = int(datetime.date(2019,4,1).strftime(\"%s\")) #today\n",
    "coin = 'BTC'\n",
    "coinID = '1182'\n",
    "timeperiod = 'histohour'\n",
    "timefrequency = 'hour'\n",
    "agg = 1\n",
    "apiKey = 'bf7c04a024b244dea99e95798fa8e102b7c9738c0933795253c2c8f39f2d160c'\n",
    "cat = 'BTC'\n",
    "lang = 'EN'\n",
    "\n",
    "coin_price = get_df_spec(fromdate, todate, timeperiod, coin, apiKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19687, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def price_to_return(df, target_col):\n",
    "    # get price change\n",
    "    s_test = df[target_col]\n",
    "    log_return = np.log(s_test/s_test.shift())\n",
    "    df['price change'] = log_return\n",
    "\n",
    "    # feature extraction from OHLC\n",
    "    # '''high/open'''\n",
    "    df['high/open'] = np.log(df['high']/df['open'])\n",
    "    # '''low/open'''\n",
    "    df['low/open'] = np.log(df['low']/df['open'])\n",
    "    # '''close/high'''\n",
    "    df['close/high'] = np.log(df['close']/df['high'])\n",
    "    # '''close/low'''\n",
    "    df['close/low'] = np.log(df['close']/df['low'])\n",
    "    df = df.drop(['close','high','low','open','volumefrom'],axis=1)\n",
    "    df.rename(columns = {'volumeto':'volumn'},inplace=True)\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "coin_return = price_to_return(coin_price,'close')\n",
    "coin_return.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out duplicates\n",
    "lst = list(coin_return.time.value_counts()[coin_return.time.value_counts() > 1].index)\n",
    "coin_return = coin_return[((coin_return['price change'] == 0.0) & (coin_return.time.isin(lst)) ==False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19678, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin_return.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEWS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv('all_news.csv')\n",
    "news['time'] = news['published_on'].apply(lambda x: datetime.datetime.fromtimestamp(x).strftime(\"%Y-%m-%d\"))\n",
    "news = news.set_index('time')\n",
    "\n",
    "# get vader sentiment score on news content\n",
    "news['vader_polarity'] = news['news_content'].apply(lambda x: sia.polarity_scores(x))\n",
    "news['vader_compound'] = news['vader_polarity'].apply(lambda x: x['compound'])\n",
    "news['vader_neg'] = news['vader_polarity'].apply(lambda x: x['neg'])\n",
    "news['vader_neu'] = news['vader_polarity'].apply(lambda x: x['neu'])\n",
    "news['vader_pos'] = news['vader_polarity'].apply(lambda x: x['pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = news[['id','published_on','vader_compound','vader_neg','vader_neu','vader_pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_sentiment(df,news):\n",
    "    holder = []\n",
    "    for i in range(df.shape[0]):\n",
    "        to_t = df.time[i]\n",
    "        from_t = to_t - 86400\n",
    "        news_interval = news[(news['published_on'] >= from_t) & (news['published_on'] <= to_t)]\n",
    "        score = news_interval.mean()[-4:]\n",
    "        score['time'] = to_t\n",
    "        holder.append(score)\n",
    "    score_df = pd.concat(holder,axis=1).T\n",
    "    score_df['time'] = score_df['time'].apply(int)\n",
    "    complete_df = pd.merge(df, score_df, on = 'time')\n",
    "    return complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coin_return_news = get_ticker_sentiment(coin_return,news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19678, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin_return_news.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOCIAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19688, 32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin_social = get_social_df_spec(fromdate,todate,timefrequency,coinID,agg,apiKey)\n",
    "coin_social.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19679, 32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicates\n",
    "coin_social = coin_social.reset_index()\n",
    "coin_social = coin_social.drop_duplicates()\n",
    "coin_social.set_index('time',inplace = True)\n",
    "coin_social.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_social(df,coin_social):\n",
    "    coin_social = coin_social.pct_change()\n",
    "    coin_social = coin_social.add(1)\n",
    "    coin_social = np.log(coin_social)\n",
    "    coin_social = coin_social.reset_index()\n",
    "    complete_df = pd.merge(df,coin_social,on='time', how = 'inner')\n",
    "    return complete_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_complete = get_ticker_social(coin_return_news,coin_social)\n",
    "coin_complete['time'] = pd.to_datetime(coin_complete['time'], unit='s')\n",
    "coin_complete['time'] = coin_complete['time'].dt.strftime('%Y-%m-%d %r')\n",
    "coin_complete.set_index('time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19678, 42)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin_complete.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPUTE NULL VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin_complete = coin_complete.replace([np.inf, -np.inf], np.nan)\n",
    "coin_complete = coin_complete.fillna(0)\n",
    "np.any(np.isinf(coin_complete))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# def normalized_data(df):\n",
    "#     min_max_scaler = MinMaxScaler()\n",
    "#     min_max_scaler.fit_transform(df)\n",
    "    \n",
    "max_abs_scaler = MaxAbsScaler()\n",
    "temp = max_abs_scaler.fit_transform(coin_complete)\n",
    "temp = pd.DataFrame(temp,columns=coin_complete.columns)\n",
    "coin_complete = temp.set_index(coin_complete.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19678, 42)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin_complete.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series to Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_to_supervised(df,sequence_length, split_line):\n",
    "\n",
    "    temp = df.values\n",
    "    temp = temp.tolist()\n",
    "    result = []\n",
    "    for index in range(len(temp) - sequence_length):\n",
    "        result.append(temp[index: index + sequence_length])\n",
    "    data = np.array(result)\n",
    "    \n",
    "    # get x and y\n",
    "    x = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "    y = y[:, 1] #second column is the price change, which is what we want to predict\n",
    "    \n",
    "    # split train and test\n",
    "    split_line = round(split_line*df.shape[0])\n",
    "    x_train = x[:int(split_line),:]\n",
    "    y_train = y[:int(split_line)]\n",
    "    \n",
    "    x_test =  x[int(split_line):,:]\n",
    "    y_test = y[int(split_line):]\n",
    "    \n",
    "    return x_train,y_train,x_test,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keras for deep learning\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# import os\n",
    "# os.environ['KERAS_BACKEND']='tensorflow'\n",
    "\n",
    "def build_model(input_shape, hidden_size,dropout_value,activation_function, loss_function, optimizer):\n",
    "    \n",
    "    #Create a Sequential model using Keras\n",
    "    model = Sequential()\n",
    "\n",
    "    #First recurrent layer with dropout\n",
    "    model.add(Bidirectional(LSTM(hidden_size, return_sequences=True), input_shape=(input_shape[1], input_shape[2]),))\n",
    "    model.add(Dropout(dropout_value))\n",
    "\n",
    "    #Second recurrent layer with dropout\n",
    "    model.add(Bidirectional(LSTM((hidden_size), return_sequences=True)))\n",
    "    model.add(Dropout(dropout_value))\n",
    "\n",
    "    #Third recurrent layersequence_length\n",
    "    model.add(Bidirectional(LSTM(hidden_size, return_sequences=False)))\n",
    "\n",
    "    #Output layer (returns the predicted value)\n",
    "    model.add(Dense(units=1))\n",
    "    \n",
    "    #Set activation function\n",
    "    model.add(Activation(activation_function))\n",
    "\n",
    "    #Set loss function and optimizer\n",
    "    model.compile(loss=loss_function, optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def fit_model(model, X_train, Y_train, batch_num, num_epoch, val_split):\n",
    "    \"\"\"\n",
    "    Fits the model to the training data\n",
    "    \n",
    "    Arguments:\n",
    "    model -- The previously initalized 3 layer Recurrent Neural Network\n",
    "    X_train -- A tensor of shape (2400, 49, 35) that represents the x values of the training data\n",
    "    Y_train -- A tensor of shape (2400,) that represents the y values of the training data\n",
    "    batch_num -- An integer representing the batch size to be used, in this case 1024\n",
    "    num_epoch -- An integer defining the number of epochs to be run, in this case 100\n",
    "    val_split -- A decimal representing the proportion of training data to be used as validation data\n",
    "    \n",
    "    Returns:\n",
    "    model -- The 3 layer Recurrent Neural Network that has been fitted to the training data\n",
    "    training_time -- An integer representing the amount of time (in seconds) that the model was training\n",
    "    \"\"\"\n",
    "    #Record the time the model starts training\n",
    "    start = time.time()\n",
    "\n",
    "    #Train the model on X_train and Y_train\n",
    "    model.fit(X_train, Y_train, batch_size= batch_num, nb_epoch=num_epoch, validation_split= val_split)\n",
    "\n",
    "    #Get the time it took to train the model (in seconds)\n",
    "    training_time = int(math.floor(time.time() - start))\n",
    "    return model, training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_test, Y_test):\n",
    "\n",
    "    #Test the model on X_Test\n",
    "    y_predict = model.predict(X_test)\n",
    "    \n",
    "    # put 1 as the first element of the array as baseline\n",
    "    y_predict_trace = np.insert(y_predict,0,1)\n",
    "    Y_test_trace = np.insert(Y_test,0,1)\n",
    "    \n",
    "    # get trace\n",
    "    # since we are using log return, we use cumsum to recover the trace\n",
    "    y_predict_trace = y_predict_trace.cumsum()\n",
    "    Y_test_trace = Y_test_trace.cumsum()\n",
    "    \n",
    "    #Plot of the predicted prices versus the real prices\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(\"Bitcoin Price Over Time\")\n",
    "    plt.plot(y_predict_trace, color = 'green', label = 'Predicted Price')\n",
    "    plt.plot(Y_test_trace, color = 'red', label = 'Real Price')\n",
    "    ax.set_ylabel(\"Price (USD)\")\n",
    "    ax.set_xlabel(\"Time (Days)\")\n",
    "    ax.legend()\n",
    "    \n",
    "    return y_predict, fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BINARY PRICE TRANSFORMATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_price(y_predict, y_real):\n",
    "    \"\"\"\n",
    "    Converts percent change to a binary 1 or 0, where 1 is an increase and 0 is a decrease/no change\n",
    "    \n",
    "    Arguments:\n",
    "    delta_predict -- A tensor of shape (267, 1) that represents the predicted percent change in price\n",
    "    delta_real -- A tensor of shape (267, 1) that represents the real percent change in price\n",
    "    \n",
    "    Returns:\n",
    "    delta_predict_1_0 -- A tensor of shape (267, 1) that represents the binary version of delta_predict\n",
    "    delta_real_1_0 -- A tensor of shape (267, 1) that represents the binary version of delta_real\n",
    "    \"\"\"\n",
    "    #Empty arrays where a 1 represents an increase in price and a 0 represents a decrease in price\n",
    "    y_predict_1_0 = np.empty(y_predict.shape)\n",
    "    y_real_1_0 = np.empty(y_real.shape)\n",
    "\n",
    "    #If the change in price is greater than zero, store it as a 1\n",
    "    #If the change in price is less than zero, store it as a 0\n",
    "    for i in range(y_predict.shape[0]):\n",
    "        if y_predict[i] > 0:\n",
    "            y_predict_1_0[i] = 1\n",
    "        else:\n",
    "            y_predict_1_0[i] = 0\n",
    "    for i in range(y_real.shape[0]):\n",
    "        if y_real[i] > 0:\n",
    "            y_real_1_0[i] = 1\n",
    "        else:\n",
    "            y_real_1_0[i] = 0    \n",
    "\n",
    "    return y_predict_1_0, y_real_1_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_positives_negatives(y_predict_1_0, y_real_1_0):\n",
    "    \"\"\"\n",
    "    Finding the number of false positives, false negatives, true positives, true negatives\n",
    "    \n",
    "    Arguments: \n",
    "    delta_predict_1_0 -- A tensor of shape (267, 1) that represents the binary version of delta_predict\n",
    "    delta_real_1_0 -- A tensor of shape (267, 1) that represents the binary version of delta_real\n",
    "    \n",
    "    Returns:\n",
    "    true_pos -- An integer that represents the number of true positives achieved by the model\n",
    "    false_pos -- An integer that represents the number of false positives achieved by the model\n",
    "    true_neg -- An integer that represents the number of true negatives achieved by the model\n",
    "    false_neg -- An integer that represents the number of false negatives achieved by the model\n",
    "    \"\"\"\n",
    "    #Finding the number of false positive/negatives and true positives/negatives\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    true_neg = 0\n",
    "    false_neg = 0\n",
    "    for i in range(y_real_1_0.shape[0]):\n",
    "        real = y_real_1_0[i]\n",
    "        predicted = y_predict_1_0[i]\n",
    "        if real == 1:\n",
    "            if predicted == 1:\n",
    "                true_pos += 1\n",
    "            else:\n",
    "                false_neg += 1\n",
    "        elif real == 0:\n",
    "            if predicted == 0:\n",
    "                true_neg += 1\n",
    "            else:\n",
    "                false_pos += 1\n",
    "    return true_pos, false_pos, true_neg, false_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def calculate_statistics(true_pos, false_pos, true_neg, false_neg, y_predict, Y_test):\n",
    "    \"\"\"\n",
    "    Calculate various statistics to assess performance\n",
    "    \n",
    "    Arguments:\n",
    "    true_pos -- An integer that represents the number of true positives achieved by the model\n",
    "    false_pos -- An integer that represents the number of false positives achieved by the model\n",
    "    true_neg -- An integer that represents the number of true negatives achieved by the model\n",
    "    false_neg -- An integer that represents the number of false negatives achieved by the model\n",
    "    Y_test -- A tensor of shape (267, 1) that represents the normalized y values of the testing data\n",
    "    y_predict -- A tensor of shape (267, 1) that represents the normalized y values of the model's predictions\n",
    "    \n",
    "    Returns:\n",
    "    precision -- How often the model gets a true positive compared to how often it returns a positive\n",
    "    recall -- How often the model gets a true positive compared to how often is hould have gotten a positive\n",
    "    F1 -- The weighted average of recall and precision\n",
    "    Mean Squared Error -- The average of the squares of the differences between predicted and real values\n",
    "    \"\"\"\n",
    "    precision = float(true_pos) / (true_pos + false_pos)\n",
    "    recall = float(true_pos) / (true_pos + false_neg)\n",
    "    F1 = float(2 * precision * recall) / (precision + recall)\n",
    "    #Get Mean Squared Error\n",
    "    MSE = mean_squared_error(y_predict.flatten(), Y_test.flatten())\n",
    "\n",
    "    return precision, recall, F1, MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTUAL TRAIN/TEST/EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((15742, 49, 42), (15742,), (3886, 49, 42), (3886,))\n"
     ]
    }
   ],
   "source": [
    "#parameters\n",
    "sequence_length = 50\n",
    "window = sequence_length -1\n",
    "train_test_split = 0.8\n",
    "hidden_size = 50\n",
    "dropout_rate = 0.3\n",
    "activation = 'linear'\n",
    "loss = 'mse'\n",
    "optimizer = 'adam'\n",
    "batch = 1024\n",
    "epoch = 100\n",
    "val_split = 0.2\n",
    "\n",
    "#data\n",
    "coin_data = coin_complete\n",
    "\n",
    "#to_supervised\n",
    "X_train, Y_train, X_test, Y_test = time_series_to_supervised(coin_data,sequence_length,train_test_split)\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/michaelyang/.conda/envs/CryptoCurrency_Project/lib/python2.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/michaelyang/.conda/envs/CryptoCurrency_Project/lib/python2.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/michaelyang/.conda/envs/CryptoCurrency_Project/lib/python2.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nbidirectional (Bidirectional (None, 49, 100)           37200     \n_________________________________________________________________\ndropout (Dropout)            (None, 49, 100)           0         \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 49, 100)           60400     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 49, 100)           0         \n_________________________________________________________________\nbidirectional_2 (Bidirection (None, 100)               60400     \n_________________________________________________________________\ndense (Dense)                (None, 1)                 101       \n_________________________________________________________________\nactivation (Activation)      (None, 1)                 0         \n=================================================================\nTotal params: 158,101\nTrainable params: 158,101\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "coin_model = build_model(X_train.shape,hidden_size,dropout_rate, activation,loss,optimizer)\n",
    "print (coin_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0405 17:56:58.549646 140292709898048 training.py:692] The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12593 samples, validate on 3149 samples\n",
      "Epoch 1/100\n",
      "12593/12593 [==============================] - 21s 2ms/sample - loss: 0.0230 - val_loss: 0.0029\n",
      "Epoch 2/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0070 - val_loss: 0.0019\n",
      "Epoch 3/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0065 - val_loss: 0.0019\n",
      "Epoch 4/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 5/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 6/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 7/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 8/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 9/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 10/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 11/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 12/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 13/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 14/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 15/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 16/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 17/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 18/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 19/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 20/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 21/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 22/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 23/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 24/100\n",
      "12593/12593 [==============================] - 19s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 25/100\n",
      "12593/12593 [==============================] - 19s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 26/100\n",
      "12593/12593 [==============================] - 19s 1ms/sample - loss: 0.0062 - val_loss: 0.0019\n",
      "Epoch 27/100\n",
      "12593/12593 [==============================] - 19s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 28/100\n",
      "12593/12593 [==============================] - 19s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 29/100\n",
      "12593/12593 [==============================] - 19s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 30/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 31/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 32/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 33/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 34/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 35/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0019\n",
      "Epoch 36/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 37/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 38/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 39/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 40/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 41/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 42/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 43/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 44/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 45/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 46/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 47/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 48/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 49/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 50/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 51/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0019\n",
      "Epoch 52/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 53/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 54/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 55/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 56/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0019\n",
      "Epoch 57/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 58/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 59/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 60/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 61/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 62/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 63/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 64/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 65/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 66/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 67/100\n",
      "12593/12593 [==============================] - 19s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 68/100\n",
      "12593/12593 [==============================] - 19s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 69/100\n",
      "12593/12593 [==============================] - 20s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 70/100\n",
      "12593/12593 [==============================] - 20s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 71/100\n",
      "12593/12593 [==============================] - 20s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 72/100\n",
      "12593/12593 [==============================] - 20s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 73/100\n",
      "12593/12593 [==============================] - 20s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 74/100\n",
      "12593/12593 [==============================] - 20s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 75/100\n",
      "12593/12593 [==============================] - 20s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "12593/12593 [==============================] - 20s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 77/100\n",
      "12593/12593 [==============================] - 20s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 78/100\n",
      "12593/12593 [==============================] - 20s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 79/100\n",
      "12593/12593 [==============================] - 20s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 80/100\n",
      "12593/12593 [==============================] - 20s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 81/100\n",
      "12593/12593 [==============================] - 19s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "12593/12593 [==============================] - 20s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 83/100\n",
      "12593/12593 [==============================] - 20s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 84/100\n",
      "12593/12593 [==============================] - 20s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 85/100\n",
      "12593/12593 [==============================] - 20s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 86/100\n",
      "12593/12593 [==============================] - 20s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 87/100\n",
      "12593/12593 [==============================] - 20s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 88/100\n",
      "12593/12593 [==============================] - 19s 2ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 89/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 90/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 91/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0019\n",
      "Epoch 92/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 93/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0061 - val_loss: 0.0018\n",
      "Epoch 94/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0061 - val_loss: 0.0018\n",
      "Epoch 95/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0061 - val_loss: 0.0018\n",
      "Epoch 96/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0061 - val_loss: 0.0019\n",
      "Epoch 97/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0019\n",
      "Epoch 98/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 99/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0061 - val_loss: 0.0018\n",
      "Epoch 100/100\n",
      "12593/12593 [==============================] - 18s 1ms/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Training time 1840 seconds\n"
     ]
    }
   ],
   "source": [
    "# model, training_time = fit_model(coin_model,X_train,Y_train,batch,epoch, val_split)\n",
    "# model.save('coin_model_1.h5')\n",
    "# print (\"Training time\", training_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unexpected keyword argument passed to optimizer: learning_rate",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-fa29be529481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'coin_model_1.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#y_predict, fig = test_model(model,X_test,Y_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelyang/.conda/envs/CryptoCurrency_Project/lib/python2.7/site-packages/tensorflow/python/keras/engine/saving.pyc\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0moptimizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m       optimizer = optimizers.deserialize(\n\u001b[0;32m--> 249\u001b[0;31m           optimizer_config, custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m       \u001b[0;31m# Recover loss functions and metrics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelyang/.conda/envs/CryptoCurrency_Project/lib/python2.7/site-packages/tensorflow/python/keras/optimizers.pyc\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    836\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m       printable_module_name='optimizer')\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelyang/.conda/envs/CryptoCurrency_Project/lib/python2.7/site-packages/tensorflow/python/keras/utils/generic_utils.pyc\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    192\u001b[0m                 list(custom_objects.items())))\n\u001b[1;32m    193\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m       \u001b[0;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelyang/.conda/envs/CryptoCurrency_Project/lib/python2.7/site-packages/tensorflow/python/keras/optimizers.pyc\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    157\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelyang/.conda/envs/CryptoCurrency_Project/lib/python2.7/site-packages/tensorflow/python/keras/optimizers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lr, beta_1, beta_2, epsilon, decay, amsgrad, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m                \u001b[0mamsgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                **kwargs):\n\u001b[0;32m--> 471\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iterations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelyang/.conda/envs/CryptoCurrency_Project/lib/python2.7/site-packages/tensorflow/python/keras/optimizers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         raise TypeError('Unexpected keyword argument '\n\u001b[0;32m---> 68\u001b[0;31m                         'passed to optimizer: ' + str(k))\n\u001b[0m\u001b[1;32m     69\u001b[0m       \u001b[0;31m# checks that clipnorm >= 0 and clipvalue >= 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unexpected keyword argument passed to optimizer: learning_rate"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('coin_model_1.h5')\n",
    "#y_predict, fig = test_model(model,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3886, 1)\n",
      "(3886,)\n"
     ]
    }
   ],
   "source": [
    "y_predict_10, y_actual_10 = binary_price(y_predict,Y_test)\n",
    "print (y_predict_10.shape)\n",
    "print (y_actual_10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives: 1212\n",
      "False positives: 1138\n",
      "True negatives: 784\n",
      "False negatives: 752\n"
     ]
    }
   ],
   "source": [
    "true_pos, false_pos, true_neg, false_neg = find_positives_negatives(y_predict_10, y_actual_10)\n",
    "print (\"True positives:\", true_pos)\n",
    "print (\"False positives:\", false_pos)\n",
    "print (\"True negatives:\", true_neg)\n",
    "print (\"False negatives:\", false_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
